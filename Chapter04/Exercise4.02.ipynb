{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Pool Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$size = {(W_i - W_f) \\over S} + 1$\n",
    "* $W_i$ = width of image\n",
    "* $W_f$ = width of filter\n",
    "* $S$ = Stride"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following sets of layers and specify the shape of the output layer at the end of all the transformations, considering an input image of size 256 x 256 x 3:\n",
    "1. A convolutional layer with 16 filters of size three, and stride and padding of one.\n",
    "1. A pooling layer with a filter of size two and stride of size two as well.\n",
    "1. A convolutional layer with eight filters of size seven, stride of one, and padding of three.\n",
    "1. A pooling layer with a filter of size two and a stride of two as well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After first layer\n",
    "A convolutional layer with 16 filters of size three, and stride and padding of one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "\n",
    "image_size = [256, 256, 3]\n",
    "num_filters = 16\n",
    "filter_size = [3, 3, 3]\n",
    "stride = 1\n",
    "padding = 1\n",
    "\n",
    "output_width = ceil((image_size[0] - filter_size[0] + 2 * padding) / stride + 1)\n",
    "output_height = ceil((image_size[1] - filter_size[1] + 2 * padding) / stride + 1)\n",
    "output_depth = ceil(image_size[2]/filter_size[2]) * num_filters\n",
    "\n",
    "dims_1 = (output_width, output_height, output_depth)\n",
    "dims_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After second layer\n",
    "A pooling layer with a filter of size two and stride of size two as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128, 16)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = dims_1 #(256, 256, 16)\n",
    "filters_size = [2, 2]\n",
    "stride = 2\n",
    "\n",
    "output_width = ceil((input_size[0] - filter_size[0]) / stride + 1)\n",
    "output_height = ceil((input_size[1] - filter_size[1]) / stride + 1)\n",
    "output_depth = input_size[2]\n",
    "\n",
    "dims_2 = (output_width, output_height, output_depth)\n",
    "dims_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After third layer\n",
    "A convolutional layer with eight filters of size seven, stride of one, and padding of three\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "input_size = dims_2 #(128, 128, 16)\n",
    "num_filters = 8\n",
    "filter_size = [7, 7, 16]\n",
    "stride = 1\n",
    "padding = 3\n",
    "\n",
    "output_width = ceil((input_size[0] - filter_size[0] + 2 * padding) / stride + 1)\n",
    "output_height = ceil((input_size[1] - filter_size[1] + 2 * padding) / stride + 1)\n",
    "output_depth = ceil(input_size[2]/filter_size[2]) * num_filters\n",
    "\n",
    "dims_3 = (output_width, output_height, output_depth)\n",
    "dims_3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After fourth (final) layer\n",
    "A pooling layer with a filter of size two and a stride of two as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = dims_3 #(128, 128, 8)\n",
    "filter_size = [2, 2]\n",
    "stride = 2\n",
    "\n",
    "output_width = ceil((input_size[0] - filter_size[0]) / stride + 1)\n",
    "output_height = ceil((input_size[1] - filter_size[1]) / stride + 1)\n",
    "output_depth = input_size[2]\n",
    "\n",
    "dims_4 = (output_width, output_height, output_depth)\n",
    "dims_4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
